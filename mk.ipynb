{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./examples/visualization.jpg \"Visualization\"\n",
    "[image2]: ./examples/grayscale.jpg \"Grayscaling\"\n",
    "[image3]: ./examples/random_noise.jpg \"Random Noise\"\n",
    "[image4]: ./examples/placeholder.png \"Traffic Sign 1\"\n",
    "[image5]: ./examples/placeholder.png \"Traffic Sign 2\"\n",
    "[image6]: ./examples/placeholder.png \"Traffic Sign 3\"\n",
    "[image7]: ./examples/placeholder.png \"Traffic Sign 4\"\n",
    "[image8]: ./examples/placeholder.png \"Traffic Sign 5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Traffic Sign Recognition** \n",
    "\n",
    "---\n",
    "\n",
    "**Build a Traffic Sign Recognition Project**\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "* Load the data set (see below for links to the project data set)\n",
    "* Explore, summarize and visualize the data set\n",
    "* Design, train and test a model architecture\n",
    "* Use the model to make predictions on new images\n",
    "* Analyze the softmax probabilities of the new images\n",
    "* Summarize the results with a written report\n",
    "\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image11]: ./examples/all_class_traffic_types.png \"all_class_traffic_types\"\n",
    "[image12]: ./examples/classes_distribution.jpg \"classes_distribution\"\n",
    "[image2]: ./examples/src_gray.jpg \"Grayscaling\"\n",
    "[image3]: ./examples/random_noise.jpg \"Random Noise\"\n",
    "[image4]: ./examples/train_accuracy.jpg \"train_accuracy\"\n",
    "[image5]: ./examples/New_Images.jpg \"New_Images\"\n",
    "[image6]: ./examples/predict_images.jpg \"predict_images\"\n",
    "[image7]: ./examples/Top_proba_new_images.jpg \"Top_proba_new_images\"\n",
    "[image8]: ./examples/placeholder.png \"Traffic Sign 5\"\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Data Set Summary & Exploration\n",
    "\n",
    "#### 1. Provide a basic summary of the data set. In the code, the analysis should be done using python, numpy and/or pandas methods rather than hardcoding results manually.\n",
    "\n",
    " * The size of training set, validtion set, and test set is:\n",
    "\n",
    "    Training Set:   34799 samples\n",
    "\n",
    "    Valid Set:     4410 samples\n",
    "\n",
    "    Test Set:      12630 samples\n",
    "\n",
    " * The shape of a traffic sign image is \n",
    "\n",
    "    Image Shape: (32, 32, 3)\n",
    "\n",
    " * The number of unique classes/labels in the data set is \n",
    "\n",
    "    43\n",
    "\n",
    "#### 2. Include an exploratory visualization of the dataset.\n",
    "\n",
    "Here is an exploratory visualization of the data set. It is a bar chart showing how the data ...\n",
    "\n",
    "![alt text][image11]\n",
    "\n",
    "class contribution:\n",
    "\n",
    "![alt text][image12]\n",
    "\n",
    "\n",
    "## Design and Test a Model Architecture\n",
    "\n",
    "### step1: Pre-process the Data Set\n",
    "\n",
    "As a first step, I decided to convert the images to grayscale because the gray image works well in classification, and reduce the amount of calculation. \n",
    "\n",
    "Here is an example of a traffic sign image before and after grayscaling.\n",
    "\n",
    "![alt text][image2]\n",
    "\n",
    "As a last step, I normalized the image data because normalized data is easier to converge in training.\n",
    "\n",
    "\n",
    "\n",
    "In addition, i decided to generate additional data because the data is unbalanced.(It's not work well in current project, will be update in feature)\n",
    "\n",
    "To add more data to the the data set, I used the following techniques \n",
    "\n",
    "•\tSlight random rotations\n",
    "\n",
    "•\tAdding random shadows\n",
    "\n",
    "Here is an example of an original image and an augmented image:\n",
    "\n",
    "#![image][image3]\n",
    "\n",
    "The difference between the original data set and the augmented data set is the following ... \n",
    "\n",
    "### step2:  Design model architecture\n",
    "\n",
    "my final model architecture looks like below, consisted of the following layers:\n",
    "\n",
    "| Layer         \t\t|     Description\t        \t\t\t\t\t| \n",
    "|:---------------------:|:---------------------------------------------:| \n",
    "| Input         \t\t| 32x32x3 RGB image   \t\t\t\t\t\t\t| \n",
    "| Convolution 3x3     \t| 1x1 stride, valid padding, outputs 30x30x8 \t|\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Max pooling\t      \t| 2x2 stride,  outputs 15x15x8 \t\t\t\t|\n",
    "| Dropout           | 0.5|\n",
    "| Convolution 3x3\t    | 1x1 stride, valid padding, outputs 13x13x8   |\n",
    "| RELU             |                               |\n",
    "| Max pooling        | 2x2 stride, outputs  6x6x26\n",
    "| Fully connected\t\t| 936x400        \t\t\t\t\t\t\t\t\t|\n",
    "| RELU             |                               |\n",
    "| Fully connected     | 400x120                           |\n",
    "| RELU             |                               |\n",
    "| Fully connected     | 120x84                      |\n",
    "| RELU             |                               |\n",
    "| Fully connected     | 84x43                      |\n",
    "| Softmax\t\t\t\t| 43x1        \t\t\t\t\t\t\t\t\t|\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "### step3: Train model. \n",
    "\n",
    "To train the model, I used an AdamOptimizer, and  hyperparameters shows below\n",
    "\n",
    "EPOCHS = 30\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "rate = 0.001\n",
    "\n",
    "when epoch is bigger than 10, set learn rate to 0.0001.\n",
    "\n",
    "\n",
    "My final model results were:\n",
    "* training set accuracy of 0.992\n",
    "* validation set accuracy of 0.934\n",
    "* test set accuracy of 0.935\n",
    "\n",
    "validation set accuracy shows below:\n",
    "\n",
    "![alt text][image4]\n",
    "\n",
    "### step4: Test a Model on New Images\n",
    "\n",
    "#### 1. download ten German traffic signs  on the web;\n",
    "\n",
    "Here are five German traffic signs that I found on the web:\n",
    "\n",
    "![alt text][image5]\n",
    "\n",
    "The first image might be difficult to classify because the sample of \"Speed limit(30km/h)\" in X_train is too little.\n",
    "\n",
    "#### 2. Here are the results of the prediction:\n",
    "\n",
    "![alt text][image6]\n",
    "\n",
    "Here are the results of the prediction:\n",
    "\n",
    "| Image\t\t\t        |     Prediction\t        \t\t\t\t\t|  result|\n",
    "|:---------------------:|:---------------------------------------------:|:---------------:|\n",
    "| Speed limit (30km/h)  | Speed limit (50km/h)   \t\t\t\t\t| false |\n",
    "| Pedestrians     \t    | Pedestrians \t\t\t\t\t\t\t\t| true  |\n",
    "| Turn right ahead      | Speed limit (30km/h)   \t\t\t\t\t| false |\n",
    "| Go straight or left   | Go straight or left \t\t\t\t\t\t| true  |\n",
    "| Speed limit (60km/h)  | Speed limit (60km/h)   \t\t\t\t\t| true  |\n",
    "| Children crossing     | Children crossing \t\t\t\t\t\t| true  |\n",
    "| Stop                  | Speed limit (30km/h)   \t\t\t\t    | false |\n",
    "| Yield     \t\t\t| Yield \t\t\t\t\t\t\t\t\t| true  | \n",
    "| Turn right ahead      | Turn right ahead   \t\t\t\t\t\t| true  |\n",
    "| Wild animals crossing | Wild animals crossing \t\t\t\t\t| true  |\n",
    "\n",
    "\n",
    "The model was able to correctly guess 7 of the 10 traffic signs, which gives an accuracy of 70%. \n",
    "\n",
    "This is  worse than the accuracy of the test set.\n",
    "\n",
    "#### 3.  the softmax probabilities for each prediction. \n",
    "\n",
    "For the first image, the model is relatively sure that this is a Speed limit (50km/h) sign (probability of 0.99), but the image does contain a Speed limit (30km/h) sign. it's wrong.\n",
    "\n",
    "The top five soft max probabilities were\n",
    "\n",
    "![alt text][image7]\n",
    "\n",
    "## problem: i think the project has problems is:\n",
    "\n",
    "1.train set is too small and unbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "### (Optional) Visualizing the Neural Network (See Step 4 of the Ipython notebook for more details)\n",
    "#### 1. Discuss the visual output of your trained network's feature maps. What characteristics did the neural network use to make classifications?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
