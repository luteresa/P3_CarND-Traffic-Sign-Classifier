{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./examples/visualization.jpg \"Visualization\"\n",
    "[image2]: ./examples/grayscale.jpg \"Grayscaling\"\n",
    "[image3]: ./examples/random_noise.jpg \"Random Noise\"\n",
    "[image4]: ./examples/placeholder.png \"Traffic Sign 1\"\n",
    "[image5]: ./examples/placeholder.png \"Traffic Sign 2\"\n",
    "[image6]: ./examples/placeholder.png \"Traffic Sign 3\"\n",
    "[image7]: ./examples/placeholder.png \"Traffic Sign 4\"\n",
    "[image8]: ./examples/placeholder.png \"Traffic Sign 5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Traffic Sign Recognition** \n",
    "\n",
    "---\n",
    "\n",
    "**Build a Traffic Sign Recognition Project**\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "* Load the data set (see below for links to the project data set)\n",
    "* Explore, summarize and visualize the data set\n",
    "* Design, train and test a model architecture\n",
    "* Use the model to make predictions on new images\n",
    "* Analyze the softmax probabilities of the new images\n",
    "* Summarize the results with a written report\n",
    "\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image11]: ./examples/all_class_traffic_types.jpg \"all_class_traffic_types\"\n",
    "[image12]: ./examples/classes_distribution.jpg \"classes_distribution\"\n",
    "[image2]: ./examples/src_gray.jpg \"Grayscaling\"\n",
    "[image13]: ./examples/all_Aug_class_traffic_types.jpg \"all_Aug_class_traffic_types\"\n",
    "[image14]: ./examples/classes_distribution_argu.jpg \"classes_distribution_argu\"\n",
    "[image3]: ./examples/random_noise.jpg \"Random Noise\"\n",
    "[image4]: ./examples/train_accuracy_50_128_0.0001.jpg \"train_accuracy\"\n",
    "[image5]: ./examples/New_Images.jpg \"New_Images\"\n",
    "[image6]: ./examples/predict_images.jpg \"predict_images\"\n",
    "[image7]: ./examples/Top_proba_new_images.jpg \"Top_proba_new_images\"\n",
    "[image8]: ./examples/placeholder.png \"Traffic Sign 5\"\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Data Set Summary & Exploration\n",
    "\n",
    "#### 1. Provide a basic summary of the data set. In the code, the analysis should be done using python, numpy and/or pandas methods rather than hardcoding results manually.\n",
    "\n",
    " * The size of training set, validtion set, and test set is:\n",
    "\n",
    "    Training Set:   34799 samples\n",
    "\n",
    "    Valid Set:     4410 samples\n",
    "\n",
    "    Test Set:      12630 samples\n",
    "\n",
    " * The shape of a traffic sign image is \n",
    "\n",
    "    Image Shape: (32, 32, 3)\n",
    "\n",
    " * The number of unique classes/labels in the data set is \n",
    "\n",
    "    43\n",
    "\n",
    "#### 2. Include an exploratory visualization of the dataset.\n",
    "\n",
    "Here is an exploratory visualization of the data set. It is a bar chart showing how the data ...\n",
    "\n",
    "![alt text][image11]\n",
    "\n",
    "class contribution:\n",
    "\n",
    "![alt text][image12]\n",
    "\n",
    "\n",
    "## Design and Test a Model Architecture\n",
    "\n",
    "### step1: Pre-process the Data Set\n",
    "\n",
    "#### 1.As a first step, I decided to convert the images to grayscale because the gray image works well in classification, and reduce the amount of calculation. \n",
    "\n",
    "Here is an example of a traffic sign image before and after grayscaling.\n",
    "\n",
    "![alt text][image2]\n",
    "\n",
    "#### 2.As a last step, I normalized the image data because normalized data is easier to converge in training.\n",
    "\n",
    "\n",
    "\n",
    "#### 3.In addition, i decided to do data argumentation  because the data is unbalanced and samples set if too small.\n",
    "\n",
    "To add more data to the the data set, I used the following techniques \n",
    "\n",
    "•\tSlight random rotations\n",
    "\n",
    "•\tSlight random scale\n",
    "\n",
    "•\tSlight random shift\n",
    "\n",
    "Here is an example of some augmented image:\n",
    "\n",
    "![alt text][image13]\n",
    "\n",
    "after argumentation, sample set's contribution shows below:\n",
    "\n",
    "![alt text][image14]\n",
    "\n",
    " * The size of training set, validtion set, and test set is:\n",
    "\n",
    "    Training Set:   129000 samples\n",
    "\n",
    "    Valid Set:     4410 samples\n",
    "\n",
    "    Test Set:      12630 samples\n",
    "\n",
    " * The shape of a traffic sign image is \n",
    "\n",
    "    Image Shape: (32, 32, 3)\n",
    "\n",
    " * The number of unique classes/labels in the data set is \n",
    "\n",
    "    43\n",
    "    \n",
    "### step2:  Design model architecture\n",
    "\n",
    "my final model architecture looks like below, consisted of the following layers:\n",
    "\n",
    "| Layer         \t\t|     Description\t        \t\t\t\t\t| \n",
    "|:---------------------:|:---------------------------------------------:| \n",
    "| Input         \t\t| 32x32x1 RGB image   \t\t\t\t\t\t\t| \n",
    "| Convolution 3x3x1       |1x1 stride, valid padding,outputs 30x30x8    |\n",
    "| RELU              |                               |\n",
    "| Dropout           | 0.5|\n",
    "| Convolution 3x3x8     \t| 1x1 stride, valid padding, outputs 28x28x26 \t|\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Max pooling\t      \t| 2x2 stride,  outputs 14x14x26 \t\t\t\t|\n",
    "| Dropout           | 0.5|\n",
    "| Convolution 3x3x26\t    | 1x1 stride, valid padding, outputs 12x12x60   |\n",
    "| RELU             |                               |\n",
    "| Max pooling        | 2x2 stride, outputs  6x6x60\n",
    "| Fully connected\t\t| inputs 2160, outputs 400        \t\t\t\t\t\t\t\t\t|\n",
    "| RELU             |                               |\n",
    "| Fully connected     | inputs 400, outputs 120                           |\n",
    "| RELU             |                               |\n",
    "| Fully connected     | intputs 120, outputs 84                      |\n",
    "| RELU             |                               |\n",
    "| Fully connected     | inputs 84, outputs 43                      |\n",
    "| Softmax\t\t\t\t| 43x1        \t\t\t\t\t\t\t\t\t|\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "### step3: Train model. \n",
    "\n",
    "To train the model, I used an AdamOptimizer, and  hyperparameters shows below\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "rate = 0.0009\n",
    "\n",
    "when epoch is bigger than 10, set learn rate to 0.0001.\n",
    "\n",
    "\n",
    "My final model results were:\n",
    "* training set accuracy of 1.0\n",
    "* validation set accuracy of 0.946\n",
    "* test set accuracy of 0.937\n",
    "\n",
    "validation set accuracy shows below:\n",
    "\n",
    "![alt text][image4]\n",
    "\n",
    "#### to train model, i take some steps:\n",
    "\n",
    "First, i use LeNet-5 to train model on source train set, validation accuracy is about 0.87.\n",
    "\n",
    "Then, to inprove the accuracy, i modify the LeNet Model, add a convolution layer and a fully connected layer. the accuracy on validation is over 0.93, however, predict new images is too bad.\n",
    "\n",
    "analysis predict images and train images, I find some class images is to small,so I do argumentation that make all class type images's count is 3000.\n",
    "\n",
    "In addition, the result of train shows the accuracy of train is 1.0, but test accuracy 's not over 0.93. So,I add  two Dropout layer to model architecture.\n",
    "\n",
    "then, I did lots of experiments, adjusted the hyperparameters. Finally, i find the model works well when set EPOCHS=50,BATCH_SIZE = 128,rate = 0.0009.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### step4: Test a Model on New Images\n",
    "\n",
    "#### 1. download ten German traffic signs  on the web;\n",
    "\n",
    "Here are five German traffic signs that I found on the web:\n",
    "\n",
    "![alt text][image5]\n",
    "\n",
    "question:\n",
    "\n",
    "1. the backgroud of images is pure white, are different frome the images in train set.\n",
    "\n",
    "2.The image Speed limit(30km/h) might be difficult to classify because the sample of \"Speed limit(30km/h)\" in X_train is too little.\n",
    "\n",
    "#### 2. Here are the results of the prediction:\n",
    "\n",
    "\n",
    "Here are the results of the prediction:\n",
    "\n",
    "| Image\t\t\t        |     Prediction\t        \t\t\t\t\t|  result|\n",
    "|:---------------------:|:---------------------------------------------:|:---------------:|\n",
    "| Yield     \t\t\t| Yield \t\t\t\t\t\t\t\t\t| true  | \n",
    "| Speed limit (30km/h)  | Speed limit (30km/h)   \t\t\t\t\t| true |\n",
    "| Go straight or left   | Go straight or left \t\t\t\t\t\t| true  |\n",
    "| General caution      | General caution \t\t\t\t\t\t| true  |\n",
    "| Wild animals crossing | Wild animals crossing \t\t\t\t\t| true  |\n",
    "\n",
    "![alt text][image6]\n",
    "The model was able to correctly predict 5 of the 5 traffic signs, which gives an accuracy of 100%. \n",
    "\n",
    "\n",
    "#### 3.  the softmax probabilities for each prediction. \n",
    "\n",
    "\n",
    "The top five soft max probabilities were\n",
    "\n",
    "![alt text][image7]\n",
    "\n",
    "my question: why the probability is 1.0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "### (Optional) Visualizing the Neural Network (See Step 4 of the Ipython notebook for more details)\n",
    "#### 1. Discuss the visual output of your trained network's feature maps. What characteristics did the neural network use to make classifications?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Can you give me some examples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "# Others:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Actually the best is if the training set is balanced, otherwise it is possible that the model will be biased towards the most frequent classes. So make the distribution as uniform as possible. For this you can use the idea from your second question.\n",
    "\n",
    "2. Actually the idea you described is an often used technique in ML, and it is called Augmentation. \n",
    "There are many different methods how you can add new artificially made images. Just a few of them:\n",
    "•\tSlight random rotations\n",
    "•\tSlight random translations\n",
    "•\tSlight affine transformations\n",
    "•\tFlipping the image (if the flipped image trivially belong to the same class)\n",
    "•\tAdding noise (salt-and-pepper, Gauss, etc...)\n",
    "•\tAdding random shadows\n",
    "•\tMaking the image brighter/darker\n",
    "•\tChanging the contrast in the image\n",
    "•\t...\n",
    "I think this article can be interesting and relevant for you:\n",
    "\n",
    "Dealing with unbalanced data\n",
    "\n",
    "https://medium.com/@vivek.yadav/dealing-with-unbalanced-data-generating-additional-data-by-jittering-the-original-image-7497fe2119c3\n",
    "\n",
    "## 调参技巧：\n",
    "\n",
    "1.Here is a discussion on how to choose the batch size of Stochastic Gradient Decent.\n",
    "\n",
    "https://stats.stackexchange.com/questions/140811/how-large-should-the-batch-size-be-for-stochastic-gradient-descent\n",
    "\n",
    "2.Here is a discussion on the Adam Optimizer.\n",
    "\n",
    "http://ruder.io/optimizing-gradient-descent/index.html#adam\n",
    "\n",
    "3.For hyperparameter optimization, you can refer to this source.\n",
    "\n",
    "http://cs231n.github.io/neural-networks-3/#hyper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
